---
title: "Applying a Multiverse to Population Habitat Analyses"
author1: "Benjamin Michael Marshall*"
author2: "Alexander Bradley Duthie**"
affiliation1: "Biological and Environmental Sciences, Faculty of Natural Sciences, University of Stirling, Stirling, FK9 4LA, Scotland, UK"
affiliation2: "-"
corresponding1: "benjaminmichaelmarshall@gmail.com"
corresponding2: "alexander.duthie@stir.ac.uk"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    template: main.tex
    keep_tex: true
    highlight: monochrome
    fig_caption: true
    dev: pdf
  bookdown::html_document2:
    theme: yeti
    highlight: monochrome
    fig_caption: true
link-citations: yes
linkcolor: gray
bibliography: [multiversePop_refs.bib, packages_refs.bib]
csl: peerj.csl
editor_options: 
  markdown: 
    wrap: sentence
abstract: Science strives to be repeatable and reproducible, but we know that different researchers will reach different conclusions even when presented with the same data and questions. This variation due to different choices researchers make during study and analysis may play a role in increasing the variation in results. Variation in results may be particularly pronounced in disciplines with high task uncertainty and difficult-to-control experiment environments, such as ecology. Much of ecological research is concerned with conservation, and a key component of animal conservation is determining animals' habitat requirements that can steer effective habitat protection. Insights into habitat requirements can be gained via the examination of animal movement, but the translation of movement data to usable estimates of habitat selection can be approached in many ways. We use a multiverse approach to explore a suite of possible habitat selection approaches, and determine the chances of incorrectly identifying habitat selection in two simulated scenarios. We find that the majority of different analysis pathways correctly identify selection, but the strength of that selection is susceptible to analysis choice. We identify several choices that have disproportionate impacts on selection estimates, with some choices having contrasting impacts depending on the analysis approach. Overall our results suggest that while we can be broadly confident in the conclusions drawn from habitat selection studies, we cannot ignore analysis choices, especially when the strength of selection is of particular concern.
keywords: Movement ecology, simulation, compositional, step selection function, two-step, poisson, habitat preference, habitat selection, animal movement, multiverse, research choice, researcher degrees for freedom
---

# Introduction

<!-- * science relies on repeatability -->

The application of science to policy is reliant on results being repeatable, reliable, and generalisable.
Efforts to achieve this often consistent of removing idiosyncrasies of studies; we remove confounding variables, control for non-target variables; and conduct replicants.
Despite our best efforts we can never create a fully generalisable study.

<!-- * exploring why things are and are not repeatable is important -->

The vast majority of the time our efforts to account for study-specific variation appear adequate, resulting in answers that can form the foundations of further studies.
However, the re-examination of foundational work reveals the need to repeatedly question and retest the assumptions subsequent work relies upon.

<!-- or whether the model used to study said system was correct - Devezer et al2021 -->

While other disciplines' replication rates have been more closely examined [@open_science_collaboration_estimating_2015; @freedman_economics_2015; see @kelly_rate_2019 for ecological replication rates], there is evidence that biology, ecology and evolution studies require similar scrutiny with regards to reliability as many of the same incentive structures seen as responsible exist [@Brembs2018; @fanelli_pressures_2010; @smaldino_natural_2016; @ware_significance_2015].
Replication studies and meta-analyses have shown previously that results in ecology and evolution may need further study [@parker_what_2013; @seguin_no_2012; @sanchez-tojar_meta-analysis_2018].
In general, it appears that initial findings are more extreme than subsequently findings, and that their initial momentum in regards to research direction is slow to reorient [@jennions_relationships_2002; @barto_dissemination_2012].

<!-- * for some disciplines testing repeatability practically is tricky, therefore we must be sure to maximise the utility of existing data and know it's limitations -->

For disciplines where direct replications are more common and feasible, replication efforts can play a feedback role in science [@open_science_collaboration_estimating_2015; @freedman_economics_2015; @peterson_self-correction_2021].
Ecological systems are complex and impossible to fully control leading to ecologists' frequent reliance on "natural experiments".

<!-- peterson pano 2021 has a bit about "task uncertainty" where high perfectly describes ecology and the hard to control system -->
Natural experiments by their nature are impossible to replicate perfectly, forcing ecology to rely on conceptual or quasi replications [@fraser_role_2020; @palmer_quasi-replication_2000].
In broader terms, undertaking studies in which subject and method differ from the original study, where the research questions are conceptually similar [@kelly_rate_2019; @nakagawa_replicating_2015].
These replication efforts are still valuable, and valued by the scientific community [@fraser_role_2020], while also aiding to gauge the reliably of proposed patterns, theories, or laws.

Ecology and evolution, due to the high task uncertainty, tends towards a system of organic self-correction, where the complexity of study systems can explain away the differences between studies (i.e., inconsistencies replication), leaving the integration of past and subsequent findings more open to interpretation [@peterson_self-correction_2021]. <!-- peterson 2021 -->.

<!-- * animal movement is one such domain -->

Animal movement, like many aspects of ecology, is a field of study in which replications are difficult to conduct.
Tracking animals is costly and come with serious ethical considerations, especially for animals where the tracking equipment can impact their health, mobility, and behaviour [@portugal_externally_2022; @homberger_strong_2021; @Sperry2009].
Therefore, there comes a strong incentive to extract the maximum value for every tracked animal, and to ensure that all results are as reliable as possible.
<!-- add that the important bit is to explore uncertainty rather than find truth -->

<!-- * habitat preference/selection is key to conservation so being confident in the generalisably is important to making the correct decisions -->

The findings from animal movement studies can be linked with landscape management and integrated into conservation plans [@Fraser2018; @doherty_coupling_2018].
For the correct conservation decisions to be made they must be based on reliable information. 
A key component for protecting species is identifying that species' requirements; the examination of movement can reveal those requirements [@mueller_how_2011; @doherty_animal_2019].
Suitable habitat (as defined in various ways) is a fundamental requirement, and the protection/restoration of suitable habitat is an actionable conservation response.

<!-- * multiple analyst projects can highlight the alternative conclusions from the same dataset, multiverses are a way we can explore the options and consistency that stem from a single dataset in lieu of proper repeats -->

As demonstrated by many analyst projects, different answers can originate from the same dataset, and even the same question [e.g., @silberzahn_many_2018; @huntingtonklein_influence_2021].
Such "researcher degrees of freedom" [or flexibility in analysis; @forstmeier_detecting_2017] can be the result of differences in question interpretation [@auspurg_has_2021], as well as the analysis approach taken [@bastiaansen_time_2020; @gelman_garden_2013].
When drawing information to be used in a conservation plan, it would be advisable to know whether decisions would be different had the data been examined in a different way.
Previous explorations have shown that research degrees of freedom are sufficiently large to alter effect strength and the final conclusions [@salis_how_2021; @desbureaux_subjective_2021].

While many analyst type projects represent an ideal, actually capable of capturing the variation in results stemming from the researchers themselves, the logistics of conducting one make them less feasible on broader scales.
An alternative, albeit with its own set of limitations, would be to conduct a multiverse analysis [@steegen_increasing_2016].
Multiverse analyses consist of a suite of analysis pathways, where diverging analysis decisions create a compounding set of possible answers to a given question.
Multiverses cannot provide evidence for the correct answer, but can allow researchers to explore the sensitivity of their conclusions to any number of analytical variables [@rijnhart_assessing_2021].
Part of this exploration can disentangle the variation stemming from different sampling or analysis choices, compared to variation stemming directly from the effect of interest [@steegen_increasing_2016; @forstmeier_detecting_2017; @simonsohn_small_2015].
This can be particularly true when we use the multiverse in a synthetic or simulated environment where we are able to hold the effect of interest constant.

<!-- * here we conduct a multiverse for population level habitat selection analysis, to explore how sampling and analytical decisions can impact the detection of habitat selection -->

Previously we explored how individual habitat selection estimates were impacted by decisions regarding sampling and analysis [@marshall_habitat_2024].
Broadly we found that sampling (data quantity) was more important than analysis decisions when estimating habitat selection, and that more modern analysis methods tend to produce less variable results.
Here we build upon those findings to target population level habitat selection analyses. We use simulated animal data with a known habitat preference to explore the impacts of sampling and analysis choice in recovering the direction of that predefined preference.

# Methods

``` {r openOptions, include=FALSE}
optionsCompleteList <- readRDS(here::here("data", "optionsCompleteList.rds"))
```

## Simulating the Scenarios

<!-- * Landscape simulation. -->

<!-- * abmAnimalMovement settings -->

We used the abmAnimalMovement `r paste0("v.", packageVersion("abmAnimalMovement"))` [@abmAnimalMovement] package to simulate the movement data of an animal with a predefined (i.e., known) habitat preference.
The abmAnimalMovement package provides an agent-based approach to simulating terrestrial animal movement using raster environmental data to guide the animals decisions.
We used the NLMR `r paste0("v.", packageVersion("NLMR"))` package [@NLMR] to generate the three required resource/environmental rasters: movement resistance, foraging quality, and shelter site quality.
The abmAnimalMovement package has systems for simulating activity cycles, three separate behavioural states (differing in movement characteristics and resource prioritisation), and site fidelity.
For the purposes of this study we used one of the pre-created example pseudo-species: Badger, described in the package manuscript.
In brief, the badger is a terrestrial species occupying several shelter sites, with a 8-12 hour activity cycle with minor seasonal variation, and is subject to differing movement resistance across the landscape.

For the purposes of the analysis we simplified the landscape information into categories –akin to the sort of land-use information more frequently available to researchers of animal movement.
We focused on foraging quality because it influences the greatest amounts of movement (in terms of time) compared to sheltering or exploratory movements.
We converted the continuous foraging quality raster into a binary, where higher quality areas (greater than 0.5) are classed as 2, and lower quality areas as 0.

We used that simulated landscape and abmAnimalMovement to simulate a population of  `r length(optionsCompleteList$individuals$individual)`, that was later sampled from.
All individuals of this population had the same simulation settings apart from starting location.
Therefore, the variation between individuals was due to stochasticity rather than variation in the predefined habitat preference.

## Sampling and Analysis Options

<!-- * targets construction -->

To manage the sampling of the population and the compounding growth of subsequent analysis decisions, we used the targets `r paste0("v.", packageVersion("targets"))` and tarchetypes `r paste0("v.", packageVersion("tarchetypes"))` R packages [@targets; @tarchetypes].
These packages allowed a branching workflow pipeline, while keeping track of object creation thereby optimising the compute time required to explore the multiverse of analysis choice.

### Sampling

<!-- * tracking regime -->

<!-- * sample size -->

The first decision in most animal movement studies will concern tracking regime.
This decision is frequently dictated by more practical considerations such as anatomy and behaviour of the animal, cost of the tracking devices, and environmental factors.
Here we covered a range of tracking regimes that vary in the frequency of location fixes (`r paste0(round(1/min(optionsCompleteList$regime$tf), digits = 2), " to ", round(1/max(optionsCompleteList$regime$tf), digits = 2))` points per hour), and the total duration of tracking (`r paste0(min(optionsCompleteList$regime$td), " to ", max(optionsCompleteList$regime$td))` days).
We created sub-sampled datasets based on every combination of tracking frequencies and durations, provided they would result in greater than 30 data points per individual.

An important component of assessing population level habitat selection is the number of individuals included in analysis.
Therefore, we randomly generated a number of samples from our population of `r length(optionsCompleteList$individuals$individual)` simulated individuals.
We varied these samples sizes from `r paste0(min(sapply(optionsCompleteList$samples, length)), " to ", max(sapply(optionsCompleteList$samples, length)))` individuals, and ran `r optionsCompleteList$repeats` repeats for each size.
A sample never mixed tracking regimes.

### Analysis

Building on the decisions concerning tracking regime and population sampling, our multiverse expanded dramatically by exploring four primary analysis routes.
These routes included an area based approach using Compana analysis (Compositional Analysis of Habitat Use), and three step-based approaches including averaged individual step-selection models, two-step conditional regression models, and a Poisson model.

<!-- * area based: compana, area method, contour, available points, space sampling, type II/III, compana test -->

We ran the Compana analysis using the *adehabitatHS* `r paste0("v.", packageVersion("adehabitatHS"))` [@adehabitatHS; @aebischer_compositional_1993; @johnson_comparison_1980].
Compana allows for the assessment of habitat selection of multiple animals in defined habitat types; it also allows habitat selection to be estimated at different scales.
We explored two scales in the multiverse: selection within the home range (Type III), and selection within an overall population available area (Type II).
The former design (Type III) requires availability habitats to be defined on an individual-by-individual basis, while the latter (Type II) design uses a summarised population level availability.

To define availability, we created home range polygons then sampled points within, recovering the corresponding habitat at those points.
The home range (AKA availability) polygons can be generated via many different processes.
We explored `r paste(optionsCompleteList$area$areaMethod, collapse = " and ")` (Minimum Convex Polygons, Autocorrelated Kernel Density Estimators).
We used the *ctmm* `r paste0("v.", packageVersion("ctmm"))` [@ctmm] package for the creation of AKDEs, and the  *adehabitatHR* `r paste0("v.", packageVersion("adehabitatHR"))` [@adehabitatHR] package for the MCPs.
The AKDEs required the fitting of a movement model; we fitted multiple models and selected the top scoring model by AIC.
For the best model we followed recommendations of @silva_autocorrelationinformed_2022, opting to run AKDEs as weighted and using perturbative hybrid residual maximum likelihood method (pHREML), as both these options tend to be the most robust in scenarios of lower tracking frequencies.
There are many options involved in the creation of AKDEs that could shape habitat availability and therefore estimations of selection.
We avoided a deeper exploration as the impact of the internal AKDE choices are likely smaller than those between area methods (e.g., compared to MCPs), and the relatively greater computational cost to generate AKDEs.
By comparison the MCPs have very few options impacting their creation.
Mainly MCP size varies based on the percentage of outliers excluded from the polygon area.
For all area methods we vary this percentage: `r paste(optionsCompleteList$area$areaContour, collapse = "%, ")`%, that correspond to increasingly large areas included in the availability polygon (i.e., covering areas that are less used by the individual).
We selected these contour values as they are the most frequently used in spatial studies [@crane_lots_2021].

Once we had created all areas for each individual, for every combination of tracking regime (duration x frequency, total regimes: `r nrow(optionsCompleteList$regime)`), we created the sample/population available areas by combining all polygons.
We used this combined polygon for the type II design, where all individuals have the same availability.

We used the availability polygons to define the extent within which we sampled habitat characteristics.
The habitat characteristics were extracted from the classified landscape raster at various points.
We varied both the number of points generated (`r paste0(min(optionsCompleteList$area$Method_ap), " to ", max(optionsCompleteList$area$Method_ap))`), as well as the pattern of how they were distributed within the polygon (random or stratified).

The final decision in the area based method approach was whether the Compana analysis was tested using randomisation or in a parametric fashion.
The former uses randomisation tests to estimate the habitat selection, while the latter uses chi-squared.

<!-- * ssf: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles, Model Averaging Method -->
<!-- * twoStep: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles -->
<!-- * poisson: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles -->

The other analysis pathways do not rely on an available area, instead they focus on randomly generated steps that mirror the observed movement of the animal.
As such the decisions involved in running the step-selection, two-step conditional regression, and Poisson models are largely the same.

The first decision is the number of random steps generated per observed step; we ranged this from `r paste0(min(optionsCompleteList$ssf$MethodSSF_as), " to ", max(optionsCompleteList$ssf$MethodSSF_as))`.
The generation of random steps is guided by two distributions, one describing the step lengths from the last observed location, and another describing the turn angle from the last observed direction of travel.
We chose to explore the impacts of different distributions.
For the step length we explored gamma and exponential distributions; for the turn angle we explored Von Mises and uniform.

All the step-based methods require the definition of a formula, where use/availablity is predicted by the habitat characteristics at those locations.
Model formulation opens up many possible alternative routes of analysis, but for this exploration we focused on the impacts of integrating step and turn angle interactions with habitat characteristics.
We ran two versions of all models, one with no interactions and one where both step lengths and turn angles interacting with the habitat classification.
Previous work has suggested that the integrated formulation (i.e., model with interactions) performs better, producing less biased estimates [@forester_accounting_2009].

A key component of all the population approaches is how they translate a highly structured dataset into an overall summary.
We ran individual step selection models using the amt `r paste0("v.", packageVersion("amt"))` [@amt] package, to explore summary methods (i.e., averaging regression coefficients @thurfjell_applications_2014).
The individual step selection models need to be averaged in some manner to extract a population mean selection.
We explored two simple options for achieving this: a naive mean of the final estimates (i.e., a mean of the estimated betas), and a model average using the *MuMIn* `r paste0("v.", packageVersion("MuMIn"))` package [@MuMIn].
The *MuMIn* model average approach is weighted based on AICc.
However, AICc is not directly comparable between models fitted with different datasets so this does not necessarily present a solution for real datasets.
As the model formulas are identically complex and the datasets equal in data quantity, the differences in AIC are purely describing the goodness of fit to the different individuals.
Therefore, the model average provided is weighted by model fit.

The difficulties in model averaging based on different data has led to the creation of models that account for the individual variably in the model formula.
A Two-Step Conditional Regression is one such solution, where strata (time steps) and clusters (individual animals) are accounted for [@craiu_conditional_2011].
We implemented these models using the *TwoStepCLogit* `r paste0("v.", packageVersion("TwoStepCLogit"))` [@TwoStepCLogit] package, again using the same decisions as applied in the SSF approach (except model averaging).
The Two-Step implementation in *TwoStepCLogit* required no NAs in landscape covariates.
In the rare instances where a simulated animal reached the edge of the landscape and available points were generated beyond the boundary, we repeated the random generation of points until fewer than 10 NAs existed in the data.

More recently @muff_accounting_2020 have suggested a reformulation of the step selection models to provide faster reliable estimations of population habitat selection.
The suggestion is to reformulate the model as a Poisson model, but critically with stratum-specific fixed effects.
As this would result in a large number of fixed effects, the computational cost would be large; so instead they are treated as a random effect, but to avoid excessive shrinkage to the mean a large variance prevents this.
To avoid the slow convergence of MCMC estimation, @muff_accounting_2020 made use of integrated nested Laplace approximation (INLA) to approximate the Bayesian inference required for such a reformulation.
We followed the code provided by @muff_accounting_2020 and made use of *INLA* `r paste0("v.", packageVersion("INLA"))` [@rue_approximate_2009; @lindgren_explicit_2011; @martins_bayesian_2013; @rue_bayesian_2017; @kourounis_towards_2018] to run Poisson models to estimate habitat selection.
We applied the same suite of choices as the applied to the SSF and Two-Step approaches.

## Assessing the multiverse

<!-- * spec curves -->

Specification curves provide an overview of the estimates of a given range of analyses.
Tighter more steep curves suggest greater agreement between all the analysis end points.
Here we also plotted the estimates against the different decisions that results in the estimates, allowing direct comparison on how the decision impacts the variation in the estimates.

<!-- * brm models: one per each analysis method -->

To better detect the impact of decisions, while accounting for the random variation stemming from the differences in individuals/samples, we ran a number of Bayesian Regression Models.
The Bayesian Regression Models aimed to describe how much of the deviation from a median answer could be explained by the various sampling and analysis decisions.
For each analysis route we ran a model that included tracking frequency, tracking duration, sample size, and all the corresponding analysis choices.
All continuous variables were scaled to help determine their relative importance to each other: (x - mean(x))/sd(x).

For the area based Compana approach the population effects included: the continuous variable contour (continuous); and the categoric predictors sampling pattern (random, stratified), test (randomisation, parametric), area method (AKDE, MCP), and design type (II, III).
For the step-based approaches they all included: model formula (integrated, non-integrated), step distribution (gamma, exponential), turn distribution (Von Mises, uniform).
The step-selection model approach also included: averaging method (naive, MuMIn average).

We ran the Bayesian Regression Models using the *brms* `r paste0("v.", packageVersion("brms"))` [@brms] package.
Once complete, we checked model convergence using R-hat values, ACF, and trace plots.
After assessment of the model convergence measures, we modified the running parameters to 4000 iterations, a warmup of 750, and a thinning rate of 4 for all models bar the Poisson models that instead used 20000 iterations, a warmup of 8000, and a thinning rate of 20.

# Results

``` {r allEstimates, include=FALSE, message=FALSE}
library(dplyr)
library(here)
library(readr)
areaBasedEstimateOutputs <- read_csv(here::here("data", "areaBasedEstimateOutputs.csv.gz"))
twoStepEstimateOutputs <- read_csv(here::here("data", "twoStepEstimateOutputs.csv.gz"))
poisEstimateOutputs <- read_csv(here::here("data", "poisEstimateOutputs.csv.gz"))
ssfEstimateOutputs <- read_csv(here::here("data", "ssfEstimateOutputs.csv.gz"))

methods <- c("area", "ssf", "pois", "twoStep")
fileList <- lapply(methods, function(x){
  df <- read.csv(here::here("data", paste0("significanceCounts_", x, ".csv")))
  df$Analysis <- x
  return(df)
})
names(fileList) <- c("area", "ssf", "pois", "twoStep")

estCountList <- lapply(fileList, function(x){
  x %>% 
    filter(Decision == "Tracking Duration (days)") %>% 
    summarise(total = sum(Total.Estimates)) %>% 
    pull(total)
})
names(estCountList) <- c("area", "ssf", "pois", "twoStep")
totalEstimates <- sum(unlist(estCountList))

area_ss3sig <- fileList$area %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Sample Size (n)",
         Value == "3") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

area_tesRansig <- fileList$area %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Compana Test Method",
         Value == "Randomisation") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

area_tesParasig <- fileList$area %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Compana Test Method",
         Value == "Parametric") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

area_tesRanScramsig <- fileList$area %>% 
  filter(Selection.Scenario == "Scrambled Habitat Layer (i.e., No selection)",
         Decision == "Compana Test Method",
         Value == "Randomisation") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

area_tesParaScramsig <- fileList$area %>% 
  filter(Selection.Scenario == "Scrambled Habitat Layer (i.e., No selection)",
         Decision == "Compana Test Method",
         Value == "Parametric") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

area_ss20sig <- fileList$area %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Sample Size (n)",
         Value == "20") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

ssf_ss3sig <- fileList$ssf %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Sample Size (n)",
         Value == "3") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

ssf_ss20sig <- fileList$ssf %>% 
  filter(Selection.Scenario == "Correct Habitat Layer (i.e., Positive selection)",
         Decision == "Sample Size (n)",
         Value == "20") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

ssf_ss3Scramsig <- fileList$ssf %>% 
  filter(Selection.Scenario == "Scrambled Habitat Layer (i.e., No selection)",
         Decision == "Sample Size (n)",
         Value == "3") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

ssf_ss20Scramsig <- fileList$ssf %>% 
  filter(Selection.Scenario == "Scrambled Habitat Layer (i.e., No selection)",
         Decision == "Sample Size (n)",
         Value == "20") %>% 
  mutate(inText = paste0(Significantly.Positive, "/", Total.Estimates)) %>% 
  pull(inText)

```

## Specification Curves

The specification curves provide an overview of all the analysis end points (n = `r format(totalEstimates, big.mark = ",")`).
The area based method – Compositional Analysis (Compana) – returned a median estimate that agreed with the underlying known simulation preference (i.e., preference for habitat 2; Fig. \@ref(fig:specCurveArea)), and a near zero effect for the scrambled selection scenario.
In the positive selection scenario very few estimates suggested negative selection, and those that did appeared to be extreme outliers.
When broken down by decision, all decisions except higher sample sizes and the test method, appear to have a large range in final estimates.
The sample size decisions had a clear reduction in possible answers when the sample is 15 or 20 individuals, but also a potential interaction with the test method when including 20 individuals.
Unexpectedly, the lowest sample size of 3 also led to visibly reduced estimate variation and the higher sample sizes had a lower rate of significant positive estimates (e.g., `r area_ss3sig` significant results with 3 individuals, compared to only `r area_ss20sig` with 20 individuals).
The test method presents two different outcomes, with the randomisation method presented a far tighter grouping of estimates in both selection scenarios, and with higher rates of significance in the positive selection scenario (`r area_tesRansig` compared to `r area_tesParasig`).
In the scrambled scenario, the grouping was reduced, but rates of significance were very similar (`r area_tesRanScramsig` compared to `r area_tesParaScramsig`).

```{r specCurveArea, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="A specification curve showing habitat selection estimates resulting from the Compana (area-based) analysis pathways. Every point represents a separate estimate of habitat selection. The top plot shows all estimates organised by estimate strength. The lower plot shows the same estimates, but split by the analysis or sampling decisions. Solid circles are the medians for each choice."}
knitr::include_graphics(here::here("notebook", "figures", "area_specCurve.png"))
```

The specification curve generated from summarised Step Selection Functions (SSFs), similarly revealed a median estimate that agrees well with the simulated parametrisation for both selection and scrambled scenarios (Fig. \@ref(fig:specCurveSSF)).
Also like the Compana curve, the SSF curve had far fewer results that indicated very low habitat preference in the positive selection scenario.
The majority of these lower estimates of habitat selection appeared connected to the decision to use an non-integrated (standard) model formulation, and the decision to model average weighted by AIC.
The naively model averaged estimates were also much more tightly grouped with fewer estimates failing to correctly detect positive preference; the tighter grouping was also reflected in the scrambled selection scenario.

Outside the lower estimates, the clearest structure in the estimates results from different decisions in sample size and tracking regime.
The tracking regime decisions, frequency and duration, appeared to shift the overall range of estimates but with limited impact on the variation.
By comparison, sample size increases appeared to reduce the spread of estimates produced.

Compared to the Compana analysis there was a cleaner pattern of significance, with the selection scenario having much higher rates of significant selection compared to the scrambled scenario.
We also saw a clear increase in significant answers when we increased the sample size in the selection scenario (e.g., sample size of 3 `r ssf_ss3sig` compared to 20 `r ssf_ss20sig`).

```{r specCurveSSF, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="A specification curve showing habitat selection estimates resulting from the Step-selection Function (SSF) analysis pathways. Every point represents a separate estimate of habitat selection. The top plot shows all estimates organised by estimate strength. The lower plot shows the same estimates, but split by the analysis or sampling decisions. Solid circles are the medians for each choice."}
knitr::include_graphics(here::here("notebook", "figures", "ssf_specCurve.png"))
```

The two-step model approach appeared to have had the greatest difficultly consistently detecting the positive selection, but the median selection in the positive selection scenario was still greater than the median from the scrambled scenario (Fig. \@ref(fig:specCurveTwoStep)).
Tracking frequency appeared to be a critical decision in the two-step model, with the 1 point per hour choice resulting in more detections of positive selection, and a tighter grouping of estimates.
The decision to integrate step and turn angle into the model formula appeared similarly critical.
The choice not to include the step and turn angle resulted in estimates more consistently positive in the positive selection scenario, and close to zero in the scrambled selection scenario. 
The integrated model formulation appeared to be largely responsible for the majority of the variation in estimates.
Unlike the SSF results, the Two-Step approach appeared to provide significant answers (both positively and negatively) very readily.
The balance of positively significant did appear more positive skewed in the selection scenario compared to the scrambled scenario, but all choices resulted in numbers of false positives and negatives bar the non-integrated model formulation choice.

```{r specCurveTwoStep, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="A specification curve showing habitat selection estimates resulting from the Two-step analysis pathways. Every point represents a separate estimate of habitat selection. The top plot shows all estimates organised by estimate strength. The lower plot shows the same estimates, but split by the analysis or sampling decisions. Solid circles are the medians for each choice."}
knitr::include_graphics(here::here("notebook", "figures", "twoStep_specCurve.png"))
```

The Poisson based approach, like those before, showed that the vast majority of analysis pathways will result in the correct identification of positive preference for habitat 2 (Fig. \@ref(fig:specCurvePois)), and centre on zero for the scrambled scenario.
Unlike the previous analyses, the tracking duration did not have as clear an impact on the spread of estimates.
Sample size and tracking frequency did; larger sample sizes and higher frequency led to overall decreases in estimate spread.
Of particular note is that the majority of failures to detect positive preference occured when the sample size is three and at lower tracking frequencies.
The analysis decisions appeared largely inconsequential, particularly the number of points per step.
Model formulation did have an impact, with the integrated formulation being more consistent at retrieving positive preference in the positive selection scenario, but the spread of estimates was much larger.
This spread increased associated with the integrated model formulation was similarly seen in the scrambled selection scenario, but resulted in near identical median estimates.
Unexpectedly, despite quite clear positive selection in many estimates, all estimates (regardless of scenario) were deemed not to be significant, with 95% confidence intervals overlapping zero.

```{r specCurvePois, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="A specification curve showing habitat selection estimates resulting from the Poisson analysis pathways. Every point represents a separate estimate of habitat selection. The top plot shows all estimates organised by estimate strength. The lower plot shows the same estimates, but split by the analysis or sampling decisions. Solid circles are the medians for each choice."}
knitr::include_graphics(here::here("notebook", "figures", "pois_specCurve.png"))
```

## Model Results

```{r loadModelExtracts, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# list2env(modelExtracts, envir = environment())

betasOutputs <- read.csv(here::here("data", "brmsEstResults.csv"))
r2Outputs <- read.csv(here::here("data", "brmsR2Results.csv"))

```

We also used four Bayesian Regression Models to explore the impact of different decisions (Fig. \@ref(fig:allEffectsPlot)), and whether those decisions could predict deviation from the median estimate (i.e., as a proxy for seeing which decisions lead to outlying extreme results).
The models provided a means to account for the variation that originates from stochasticity in the simulation and sampling; the sheer number of final estimates can obscure patterns in specification curves.

The conditional *R^2^* values differed for the four models, ranging from `r paste(round(range(r2Outputs$R2[r2Outputs$Component == "conditional"]), digits = 2), collapse = " to ")`, indicating a sizeable amount of variation in estimates being uncounted for by either the analysis discretions of random/group effects of sample ID, selection scenario, and species.
The Compana results model had a conditional *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "areaBrms" & r2Outputs$Component == "conditional"], digits = 2)`; whereas the SSF model returned `r round(r2Outputs$R2[r2Outputs$model == "ssfBrms" & r2Outputs$Component == "conditional"], digits = 2)`; the Two-Step model returned `r round(r2Outputs$R2[r2Outputs$model == "twoStepBrms" & r2Outputs$Component == "conditional"], digits = 2)`; and the Poisson model returned `r round(r2Outputs$R2[r2Outputs$model == "poisBrms" & r2Outputs$Component == "conditional"], digits = 2)`.

The marginal *R^2^* represents the bulk of the conditional *R^2^* for Compana and SSF models, suggesting an important role for the fixed/population effects.
The Compana results model had a conditional *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "areaBrms" & r2Outputs$Component == "marginal"], digits = 2)`; whereas the SSF model returned `r round(r2Outputs$R2[r2Outputs$model == "ssfBrms" & r2Outputs$Component == "marginal"], digits = 2)`.
The Two-Step model returned marginal *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "twoStepBrms" & r2Outputs$Component == "marginal"], digits = 2)`; and the Poisson model returned `r round(r2Outputs$R2[r2Outputs$model == "poisBrms" & r2Outputs$Component == "marginal"], digits = 2)`.
The low marginal *R^2^* in the Two-Step model highlights the greater sensitivity to variation between species, individuals and samples, compared to the variation resulting from analysis decisions.
The same is true for the Poisson model, but to a lesser degree.

The conditional *R^2^* values differed for the four models, ranging from `r paste(round(range(r2Outputs$R2[r2Outputs$Component == "conditional"]), digits = 2), collapse = " to ")`, indicating a sizeable amount of variation in estimates being uncounted for by either the analysis discrions of random/group effects of sample ID, selection scenario, and species.
The Compana results model had a conditional *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "areaBrms" & r2Outputs$Component == "conditional"], digits = 2)`; whereas the SSF model returned `r round(r2Outputs$R2[r2Outputs$model == "ssfBrms" & r2Outputs$Component == "conditional"], digits = 2)`; the Two-Step model returned `r round(r2Outputs$R2[r2Outputs$model == "twoStepBrms" & r2Outputs$Component == "conditional"], digits = 2)`; and the Poisson model returned `r round(r2Outputs$R2[r2Outputs$model == "poisBrms" & r2Outputs$Component == "conditional"], digits = 2)`.

The marginal *R^2^* represents the bulk of the conditional *R^2^* for Compana and SSF models, suggesting an important role for the fixed/population effects.
The Compana results model had a conditional *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "areaBrms" & r2Outputs$Component == "marginal"], digits = 2)`; whereas the SSF model returned `r round(r2Outputs$R2[r2Outputs$model == "ssfBrms" & r2Outputs$Component == "marginal"], digits = 2)`.
The Two-Step model returned marginal *R^2^* of `r round(r2Outputs$R2[r2Outputs$model == "twoStepBrms" & r2Outputs$Component == "marginal"], digits = 2)`; and the Poisson model returned `r round(r2Outputs$R2[r2Outputs$model == "poisBrms" & r2Outputs$Component == "marginal"], digits = 2)`.
The low marginal *R^2^* in the Two-Step model highlights the greater sensitivity to variation between species, individuals and samples, compared to the variation resulting from analysis decisions.
The same is true for the Poisson model, but to a lesser degree.

``` {r prepareInTextBetas, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}

betasOutputs <- betasOutputs %>% 
  mutate(inTextBeta = 
           paste0(
             format(round(.value, digits = 2), nsmall = 2),
             "; 95% HDCI ",
             format(round(.lower, digits = 2), nsmall = 2), " - ",
                    format(round(.upper, digits = 2), nsmall = 2)),
         betaKey = paste("beta", model, .variable, sep = "_")
           )
betaList <- setNames(split(betasOutputs$inTextBeta, seq(nrow(betasOutputs))), betasOutputs$betaKey)
list2env(betaList, envir = environment())

```

The Poisson model approach showed the most consistent benefits from more data, where all increases in sampling intensity led to marked reductions in deviation from the median estimate: sample size ($\beta$ `r beta_poisBrms_b_sampleSizeScaled`), tracking duration ($\beta$ `r beta_poisBrms_b_trackDuraScaled`), and tracking frequency ($\beta$ `r beta_poisBrms_b_trackFreqScaled`; Fig. \@ref(fig:effectPlotPois)). 
Similarly SSF methods benefited from increasing sampling duration ($\beta$ `r beta_ssfBrms_b_trackFreqScaled`) and frequency, but the impact on increasing sample size was not as apparent ($\beta$ `r beta_ssfBrms_b_trackFreqScaled`; Fig. \@ref(fig:effectPlotSSF)).
Two-Step methods appeared to benefit from increases in tracking frequency ($\beta$ `r beta_twoStepBrms_b_trackFreqScaled`), but not duration ($\beta$ `r beta_twoStepBrms_b_trackDuraScaled`) or sample size ($\beta$ `r beta_twoStepBrms_b_sampleSizeScaled`).
Potentially the benefits from some of these decisions are masked by the extreme variation in the integrated model formulation decision.
The area-based Compana approach appeared to vary more in its estimates when provided more data.
Sample size ($\beta$ `r beta_areaBrms_b_sampleSizeScaled`), tracking duration ($\beta$ `r beta_areaBrms_b_trackDuraScaled`) and tracking frequency ($\beta$ `r beta_areaBrms_b_trackFreqScaled`; Fig. \@ref(fig:effectPlotArea)) all led to increased variation from the median estimate.

<!-- NEEDS CHECKING, the spec curve shows that bizzare result -->
<!-- The Two-step approach appears the least senetivie to sampling decisions, with only tracking frequency reveal to have a clear effect (Fig. \@ref(fig:effectPlotTwoStep)). -->
<!-- Strangely the increases in tracking frequency led to a greater deviation from the median result. -->

The points per step decision made little impact on the variation of estimates in any of the step-based approaches, potentially due to the simplified nature of the landscape used (i.e., no rare habitat that would require high numbers of random points to detect).
Use of the gamma distribution, in contrast to the exponential distribution, in all the step-based approaches led to reduced deviation from the median (Poisson: ($\beta$ `r beta_poisBrms_b_stepDistgamma`); SSF: ($\beta$ `r beta_ssfBrms_b_stepDistgamma`); Two-Step: ($\beta$ `r beta_twoStepBrms_b_stepDistgamma`)).
Whereas the use of Von Mises, in contrast to a uniform distribution, failed to have a sizeable impact in Poisson ($\beta$ `r beta_poisBrms_b_turnDistvonmises`) and SSF ($\beta$ `r beta_ssfBrms_b_turnDistvonmises`) methods and led to greater variation in Two-Step estimates ($\beta$ `r beta_twoStepBrms_b_turnDistvonmises`).
The underlying simulation used a gamma distribution to generate step lengths and Von Mises for turn angles, that may partially explain this result.

The most mixed decision was the use of model formulation that includes the step and turn angles (i.e., integrated versus not integrated).
Here we saw including the step and turn angles in the model formula for the summarised SSF approach led to greater variation from the median estimate ($\beta$ `r beta_ssfBrms_b_modelFormulamf.ss`), but a contrasting effect for both the Two-step ($\beta$ `r beta_twoStepBrms_b_modelFormulamf.ss`) and Poisson approaches ($\beta$ `r beta_poisBrms_b_modelFormulamf.ss`) where the non-integrated formula tended to reduce the spread of estimates (Fig. \@ref(fig:effectPlotSSF).

The greater deviation in averaged SSFs when using the integrated formulation may be a result of its interaction with the model averaging approach. 
The naive model averaging approach led to a dramatically lower spread of estimates ($\beta$ `r beta_ssfBrms_b_averagingMethodNaiveaverage`), and avoided underestimating selection in the positive selection scenario (unlike the AIC model average approach; (Fig. \@ref(fig:specCurveSSF)).

Finally, the area based approach had a number of unique decisions.
Largely the decisions associated with defining the available area had a larger impact than those linked to generating the random points (Fig. \@ref(fig:effectPlotArea)).
In brief, the use of MCPs ($\beta$ `r beta_areaBrms_b_areaMethodMCP`) and type III designs ($\beta$ `r beta_areaBrms_b_typeIII`) tended to lead to less variable results.
Larger contours (areas) ($\beta$ `r beta_areaBrms_b_contourScaled`) and more points ($\beta$ `r beta_areaBrms_b_availablePointsScaled`) unexpectedly increased variation of estimates from the median.
The effect of larger contours and type III designs appeared to contradict each other, as both would tend towards a larger area that would presumably result in similar results.
By far the clearest result in the area-based approach was the Compana test method, where randomisation dramatically reduced the spread of estimates ($\beta$ `r beta_areaBrms_b_testrandomisation`).

```{r allEffectsPlot, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Point estimates and 95% credible intervals associated  with all population effects from the Bayesian Regression models aiming to predict deviation from the median estimate."}
knitr::include_graphics(here::here("notebook", "figures", "_allEffectsPlot.png"))
```

# Discussion

The multiverse approach highlights the diverse array of answers one can obtain even when analysing the same data, simulated using the same parameters.
Fortunately the vast majority of the answers from the `r format(totalEstimates, big.mark = ",")` analysis end points agree, and correctly recover the positive habitat selection programmed into the simulated animals in both positive selection and no selection scenarios.
This broad agreement is cause for optimism, suggesting that the potentially deviating analysis choices made by researchers largely converge to an agreement –albeit within this given simulated scenario and given habitat preference strength.
Looking back at past studies reporting habitat preference, we have have considerable confidence that different (or reported) choices during analysis likely would not have changed the overall conclusions.

<!-- sampling important, holds the biggest gains for poisson and step selection (less so for other methods) -->
Unlike previous multiverse investigations into individual selection, the largest effect on whether an estimate was close to the median estimate did not come as a result of sampling.
This is possibly due to the overall increase in data quantity that came from running a multi-individual sample, perhaps past the point of benefiting as dramatically from more data.
There was no programmed individual variation (which is a key consideration in real-world scenarios @stuber_spatial_2022), therefore any variation between individuals of the same pseudo-species was the result of stochasticity.
This lack of individuality may dampen the variation, reducing effects of increased sample sizes.
However, a failure to reduce the deviation from the median estimate does not mean that increased sample sizes were not beneficial.
Increased sample sizes may have actually led to estimates that were closer to the "true" selection of the animal, and @craiu_conditional_2011 suggests greater stability in estimates with more data.

When examining the impact of individual analysis choices, we see a few that appear to be key.
In the area based (Compana) analysis, the decision to test selection using randomisation led to dramatically more consistent estimates. 
We suspect this is due to the parametric method making more stringent assumptions regarding the data's distribution, resulting in a greater frequency of unstable outlying estimates.
For the SSF and Poisson models the decision on integrating step and turn angle into the model formulation appears critical.
For SSF is it suggested that integrating step and turn is ideal as it limits bias by accounting for the movement tendencies of the animal, particularly for high selection scenarios [@forester_accounting_2009]. 
We saw reduced extreme high and low estimates when using the integrated formulation that supports this.

Poisson models are similarly affected, but in the opposite direction.
@muff_accounting_2020 previously highlighted the potential contrasting impact of integration in the Poisson models, and our multiverse mirrors this with the integrated formulations leading to greater more variable estimates.
In the context of @muff_accounting_2020, we suspect the more outlying variable estimations are more bias results and ultimately further from the true selections strength.
The most deviated estimations appear at low or intermediate sample sizes, and low tracking frequencies for the outlying low estimates.
This could indicate that any bias resulting from the integrated formula could be mitigated with more data, but further investigation would be required to confirm this as we do not see greater tracking durations eliminating outlier estimates.
<!-- model formulation was warned against in the Poisson model describing paper - issf vs ssf, the multiverse backs that up -->
<!-- quote from muff et al paper : "In fact, we were able to obtain less biased variance estimators when we omitted the step-length variable (see Figure S2 in the Appendix). The impact of including step length in the linear predictor on the variance estimators is interesting and unexpected, and it is an apparent contrast to Forester et al. (2009), where the inclusion of step length is recommended to avoid bias in fixed-effect parameters." -->
<!-- However, it must be kept in mind that Ts.estim is an approximate procedure that does not guarantee consistent results and that it may fail to converge or even does not run, for example when at least one animal does not encounter all habitat types. -->

<!-- All variance estimators were slightly underestimated for all methods, namely because the step-length variable in the predictor absorbs some of the variability in the selection coefficients. In fact, we were able to obtain less biased variance estimators when we omitted the step-length variable (see Figure S2 in the Appendix). The impact of including step length in the linear predictor on the variance estimators is interesting and unexpected, and it is an apparent contrast to Forester et al. (2009), where the inclusion of step length is recommended to avoid bias in fixed-effect parameters. This trade-off between bias in the estimators of fixed effect parameters and the variance parameters deserves more attention in future research. -->

Outside of the decision we can compare the different approaches.
While we should be cautious comparing the different approaches as target and interpret selection in different ways, we can see that SSF, Poisson, and Compana approaches do better than the Two-Step approach when correctly identifying selection and no-selection.
The Two-Step approach appears to be overly keen to consider selection significant (in either direction), and could frequently encounter convergence issues.
The latter is likely caused by data inadequacies in either the strata or clusters [@craiu_conditional_2011]. 
Compana did appear to be more consistent than Two-Step, the SSF and Poisson approaches appear to react more predictability to improvements in data quantity and sample size.
The SSF and Poisson approaches appear to be the stronger choices and offer increased flexibility with regards to habitat classification (i.e., allow for continuous habitat variables).

## Multiverse in context

<!-- cannot examine everything -->
While multiverses can help us explore the possible answers that can come from a given dataset, they cannot provide guidance on which of those answers is correct.
The creation of the multiverse is subject to the same decision making procedure that any single given pathway is: what decisions to include, and how to vary the choices [@simonsohn_specification_2020; @del_giudice_travelers_2021].
Therefore, the overall median or mean answer is heavily dependent on the construction of the multiverse.
Additionally, the choices and resulting analysis pathways are not equally as valid, nor equally likely to be undertaken by a researcher.
This means the multiverse of answers may provide some insight on spread of estimates [@steegen_increasing_2016], but should not be directly interpreted as providing more or less support for a given estimate based on the distribution of estimates.
<!-- convergence to a common answers =/= convergence to correct answer, models better reflecting reality will be better, but in lieu of that confidence agreement is the best we have? -->
We can take this issue further, reminding ourselves that agreement is not necessarily a reliable proxy for accuracy [@devezer_case_2021].
A better model reflecting the mechanistic reality of the study system is preferable to a suite of models that agree but converge on a less accurate answer.
An example in the conducted multiverse: we used AKDEs and MCPs as two alternative definitions of availability for the area based method.
Arguably we should have excluded the MCP choice in favour of the AKDE choice, as the latter does a better job at capturing the movement processes/patterns underlying animal space-use [@Fleming2015].
Despite this, we felt, the frequency of MCP use in spatial ecology [@crane_lots_2021], warranted its inclusion as a conceivable choice.
Judgement calls such as this are unavoidable, and determining whether a model better reflects the underlying system can be exceptionally difficult outside of simulated "known-truth" scenarios.
It very well may be ideal to conduct multiple analysis as standard procedure to explore selection at different scales [@aebischer_compositional_1993].

When we are uncertain of the mechanism, or unable to truly model the vast complexity of the system (very frequent in ecology), then informed agreement may be our best option.
Recent efforts looking at how many researchers answer the same question from the same dataset reveals that these judgement calls result in different answers [@gould_same_2023].
In many ways the more organic real-world results from @gould_same_2023 reflect the multiverse results presented here –a general agreement on direction, but variation in uncertainty and magnitude.
What differs, is that here we know the simulated correct answer is a positive effect, in @gould_same_2023 the truth is unknown and so we rely on the good agreement of many independent informed analyses.
The logistics of organising 246 researchers to assess uncertainty in analyses is infeasible on a broader scale.
The multiverse approach presents a complementary method for assessing the scope of researcher choice on final results –albeit more vulnerable to the individual researcher's biases and potentially limited to analyses with lower computational costs. 

<!-- strength of selection makes exporting these results tricky -->
We have avoided suggesting rules or guides based on these results, instead suggesting broad trends.
The diverse array of species tracked and the habitats in which they reside makes specific guidance nigh impossible without informed assumptions tailored to a given study system.
We simulated a three species to try and broaden the generalisability of our findings.
However, they all shared core assumptions stemming from the agent-based simulation, namely: site fidelity, consistent cycadian cycles, and distinct behavioural states [@abmAnimalMovement].
For example, the routine use of shelter sites in a the preferred habitat would mean that missing those sites/locations is unlikely with a reasonably frequent tracking regime.
This may have dampened the benefits of tracking frequency in our scenarios, and comparatively in scenarios where the use of preferred habitat is more fleeting or temporally inconsistent tracking frequency may be more crucial.
Other studies have highlighted that certain decisions may assume increased importance in different scenarios.
The number of available points in SSF analysis becomes more important when the analysis is required to identify the use of smaller/rarer habitat types [@thurfjell_applications_2014].
Some methods, such as Resource Selection Functions, have the means of estimating the required data quantity to detect a given strength of selection in a given landscape, and provide a guide to how consistent results would be from that dataset [@street_solving_2021].
These methods still require informed decisions to be made concerning the strength of selection that is of interest as well as how to define the landscape, but complement the goal of the multiverse assessment with a more rigorously mathematical approach.

Habitat selection analyses continue to expand and develop further; for example, to better tackle the non-independence of observed animal locations while building agreement between movement (i.e., local selection) and overall habitat selection [@michelot_linking_2019; @michelot_inference_2020], integrate non-linear relationships [@klappstein_step_2024], and develop methods less influenced by data missingness [@michelot_langevin_2019; @hofmann_methods_2024].
Repeating multiverse-like assessments may present a valuable context for these analyses, which is independent of the specific modelling approach.

## Conclusions

Overall our multiverse exploration of habitat selection analyses shows that the majority of analysis pathways correctly identify the pre-programmed selection present in the simulated scenarios.
While there was broad agreement, which was enhanced in most cases with increased data, several analysis choices highlight the continued need for attention when analysing animal movement data as the impact of those choices will not be the same under different analysis approaches. 

# Acknowledgements

This work was supported by the Natural Environment Research Council (NERC) via the IAPETUS2 Doctoral Training Partnership held by Benjamin Michael Marshall (grant reference NE/S007431/1).

# Software availablity

In addition to packages already mentioned in the methods we also used the following.

We used *R* `r paste0("v.", version$major, ".", version$minor)` [@base] via *RStudio* v.2024.09.0 [@rstudio]. <!-- version has to be manually added because rstudioapi doesn't work in targets -->
We used *here* `r paste0("v.", packageVersion("here"))` [@here] and *qs* `r paste0("v.", packageVersion("qs"))` [@qs] to manage directory addresses and saved objects.

We used *raster* `r paste0("v.", packageVersion("raster"))` [@raster] and *RandomFields* `r paste0("v.", packageVersion("RandomFields"))` [@RandomFields] to aid landscape raster creation alongside NLMR `r paste0("v.", packageVersion("NLMR"))` [@NLMR].

We used *ggplot2* `r paste0("v.", packageVersion("ggplot2"))` for creating figures [@ggplot2], with the expansions: *patchwork* `r paste0("v.", packageVersion("patchwork"))` [@patchwork], *ggridges* `r paste0("v.", packageVersion("ggridges"))` [@ggridges], *ggdist* `r paste0("v.", packageVersion("ggdist"))` [@ggdist], and *ggtext* `r paste0("v.", packageVersion("ggtext"))` [@ggtext].

We used *brms* `r paste0("v.", packageVersion("brms"))` [@brms] to run Bayesian models, with diagnostics generated used *bayesplot* `r paste0("v.", packageVersion("bayesplot"))` [@bayesplot], *tidybayes* `r paste0("v.", packageVersion("tidybayes"))` [@tidybayes], and *performance* `r paste0("v.", packageVersion("performance"))` [@performance].

We used the *dplyr* `r paste0("v.", packageVersion("dplyr"))` [@dplyr], *tibble* `r paste0("v.", packageVersion("tibble"))` [@tibble],
<!-- *reshape2* `r paste0("v.", packageVersion("reshape2"))` [@reshape2], -->
and *stringr* `r paste0("v.", packageVersion("stringr"))` [@stringr] packages for data manipulation.

We used *sp* `r paste0("v.", packageVersion("sp"))` [@sp], *move* `r paste0("v.", packageVersion("move"))` [@move] for manipulation of spatial data and estimation of space use not otherwise mentioned in the methods.

We used rmarkdown `r paste0("v.", packageVersion("rmarkdown"))` [@rmarkdown2023; @rmarkdown2018; @rmarkdown2020], bookdown `r paste0("v.", packageVersion("bookdown"))` [@bookdown2016; @R-bookdown], tinytex `r paste0("v.", packageVersion("tinytex"))` [@tinytex2019; @tinytex2023], and knitr `r paste0("v.", packageVersion("knitr"))` [@knitr2015; @knitr2014; @knitr2023] packages to generate type-set outputs.

We generated R package citations with the aid of *grateful* `r paste0("v.", packageVersion("grateful"))` [@grateful].

# Data availabilty

All code used to simulate the movement data, implement the multiverse of analysis, and model the variation in resulting estimates is available at [https://github.com/BenMMarshall/multiverseHabitatPop](https://github.com/BenMMarshall/multiverseHabitatPop).
We have also archived this code at [ZENDO REPO HERE WHEN PUBLIC].
We have included further model diagnostic plots not included here in the repository.

\clearpage

# Supplementary Material

# ```{r effectPlotArea, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Point estimates and 95% credible intervals associated  with all population effects from the Bayesian Regression models aiming to predict deviation from the median estimate."}
# knitr::include_graphics(here::here("notebook", "figures", "areaBrms_effectsPlot.png"))
# ```
# 
# ```{r effectPlotSSF, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
# knitr::include_graphics(here::here("notebook", "figures", "ssfBrms_effectsPlot.png"))
# ```
# 
# ```{r effectPlotTwoStep, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
# knitr::include_graphics(here::here("notebook", "figures", "twoStepBrms_effectsPlot.png"))
# ```
# 
# ```{r effectPlotPois, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
# knitr::include_graphics(here::here("notebook", "figures", "poisBrms_effectsPlot.png"))
# ```

\clearpage

```{r directTable, echo=FALSE, message=FALSE, warning=FALSE}
allSigSummary <- do.call(bind_rows, fileList) %>% 
  mutate(Analysis = case_when(
    Analysis == "area" ~ "Compana",
    Analysis == "ssf" ~ "SSF",
    Analysis == "pois" ~ "Poisson",
    Analysis == "twoStep" ~ "TwoStep"
  )) %>% 
  select(Analysis, Selection.Scenario, Decision, Value,
  Significantly.Negative,
  Not.Significant,
  Significantly.Positive,
  Total.Estimates,
  Significance.Uncalculated
  )
allSigSummary[is.na(allSigSummary)] <- 0

write.csv(allSigSummary, here::here("data", "Table S1 - Significance Summary.csv"), row.names = FALSE)

knitr::kable(
  allSigSummary,
  caption = "An overall summary of all analyses and associated decisions in relation to the frequency of significant results.",
  format = "latex",
  align = "lcc",
  vline = "",
  toprule = "",
  midrule = "",
  linesep = "",
  bottomrule = "",
  col.names = c(
    "Analysis",
    "Selection Scenario",
    "Decision",
    "Value",
    "Significantly Negative",
    "Not Significant",
    "Significantly Positive",
    "Total Estimates",
    "Significance Uncalculated"
  )
  # escape = FALSE
) %>%
  kableExtra::kable_styling(font_size = 6, latex_options = c("scale_down"))

```

\clearpage

# References
