---
title: "Applying a Multiverse to Population Habitat Analyses"
author1: "Benjamin Michael Marshall*"
author2: "Alexander Bradley Duthie**"
affiliation1: "Biological and Environmental Sciences, Faculty of Natural Sciences, University of Stirling, Stirling, FK9 4LA, Scotland, UK"
affiliation2: "-"
corresponding1: "benjaminmichaelmarshall@gmail.com"
corresponding2: "alexander.duthie@stir.ac.uk"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    template: main.tex
    keep_tex: true
    highlight: monochrome
    fig_caption: true
    dev: pdf
  bookdown::html_document2:
    theme: yeti
    highlight: monochrome
    fig_caption: true
link-citations: yes
linkcolor: gray
bibliography: [multiversePop_refs.bib, packages_refs.bib]
csl: peerj.csl
editor_options: 
  markdown: 
    wrap: sentence
abstract: abc
keywords: Movement ecology, simulation, compana, resource selection functions, step selection function, habitat preference, habitat selection, animal movement, multiverse, research choice, researcher degrees for freedom,
---

# Introduction

* science relies on repeatability

Science is reliant on results being repeatable, reliable, and generalisable.
Efforts to achieve this often consistent of removing idiosyncrasies of studies; we remove confounding variables, control for non-target variables; and conduct replicants.
Despite best efforts we can never create a fully generalisable study.

* exploring why things are and are not repeatable is important

The vast majority of the time our efforts to account for study-specific variation appear adequate, resulting in answers that can form the foundations of further studies.
However, the re-examination of foundational work reveals the need to repeatedly question and retest the assumptions subsequent work relies upon.
While other disciplines' replication rates have been more closely examined [@open_science_collaboration_estimating_2015; @freedman_economics_2015; see @kelly_rate_2019 for ecological replication rates], there is evidence that biology, ecology and evolution studies require similar scrutiny with regards to reliable as many of the same incentive structures seen as responsible exist [@Brembs2018; @fanelli_pressures_2010; @smaldino_natural_2016; @ware_significance_2015].
Replication studies and meta-analyses have shown that previously results in ecology and evolution may need further study [@parker_what_2013; @seguin_no_2012; @sanchez-tojar_meta-analysis_2018].
In general, it appears that initial findings are more extreme than those subsequently, and that their initial momentum in regards to research direction is slow to reorient [@jennions_relationships_2002; @barto_dissemination_2012].


* for some disciplines testing repeatability practically is tricky, therefore we must be sure to maximise the utility of existing data and know it's limitations

For disciplines where direct replications are more common and feasible, replication efforts can play a feedback role in science [@open_science_collaboration_estimating_2015; @freedman_economics_2015].
Ecological systems, particularly wild, are complex and impossible to fully control leading to ecologists' frequent reliance on "natural experiments".
Natural experiments by their nature are impossible to replicate perfectly, forcing ecology to rely on conceptual or quasi replications [@fraser_role_2020; @palmer_quasi-replication_2000].
In broader terms, undertaking studies that subject and method differ from the original study, the where the research questions are conceptually similar [@kelly_rate_2019; @nakagawa_replicating_2015].
These replication efforts are still valuable, and valued by the scientific community [@fraser_role_2020], while also aiding to gauge the reliably of proposed patterns, theories, or laws.

* animal movement is one such domain

Animal movement is field of study that replications are difficult to conduct.
Tracking animals is costly and come with serious ethical considerations, especially for animals where the tracking equipment can impact their health, mobility, and behaviour [@portugal_externally_2022; @homberger_strong_2021; @Sperry2009].
Therefore, there is a strong incentive to extract the maximum value for every tracked animal, and to ensure that all results are as reliable as possible.

* habitat preference/selection is key to conservation so being confident in the generalisably is important to making the correct decisions

The findings from animal movement studies can be linked with landscape management and integrated into conservation plans [@Fraser2018; @doherty_coupling_2018].
For the correct conservation decisions to be made they must be based on reliable information. 
A key component for protecting species is identifying that species requirements; the examination of movement can reveal those requirements [@mueller_how_2011; @doherty_animal_2019].
Suitable habitat (as defined in various ways) is a fundamental requirement, and the protection/restoration of suitable habitat is an actionable conservation response.

* multiple analyst projects can highlight the alternative conclusions from the same dataset, multiverses are a way we can explore the options and consistency that stem from a single dataset in lieu of proper repeats

As demonstrated by many analyst projects different answers can originate from the same dataset, and even the same question [e.g., @silberzahn_many_2018; @huntingtonklein_influence_2021].
Such research degrees of freedom [or flexibility in analysis; @forstmeier_detecting_2017] can be the result of difference in question interpretation [@auspurg_has_2021], as well as the analysis approach taken [@bastiaansen_time_2020; @gelman_garden_2013].
When drawing information to be used in a conservation plan, it would be advisable to know whether decisions would be different had the data been examined in a different way.
Previous exploration have shown that research degrees of freedom are sufficiently large to alter effect strength and the final conclusions [@salis_how_2021; @desbureaux_subjective_2021].

While many analyst type projects represent an ideal, actually capable of capturing the variation in results stemming from the researchers themselves, the logistics of conducting one make them less feasible on broader scales.
An alternative, albeit with its own set of limitations, would be to conduct a multiverse analysis [@steegen_increasing_2016].
Multiverse analyses consistent of a suite of analysis pathways, where diverging analysis decisions create a compounding set of possible answers to a give question.
Multiverses cannot provide evidence for the correct answer, but can allow researchers to explore the sensitivity of their conclusions to any number of analytical variables [@rijnhart_assessing_2021].
Part of this exploration can disentangle the variation stemming from different sampling or analysis choices, compared to variation stemming directly from the effect of interest [@steegen_increasing_2016; @forstmeier_detecting_2017; @simonsohn_small_2015].
This can particularly true when we use the multiverse in a synthetic or simulated environment where we are able to hold the effect of interest constant.

* here we conduct a multiverse for population level habitat selection analysis, to explore how sampling and analytical decisions can impact the detection of habitat selection

Previously we explored how individual habitat selection estimates were impacted by decisions regarding sampling and analysis <!-- first multiverse preprint cite here -->.
Broadly we found that sampling (data quantity) was more important than analysis decisions when estimating habitat selection, and that more modern analysis methods tend to produce less variable results.
Here we build upon those findings to target population level habitat selection analyses. We use simulated animal data with a known habitat preference to explore the impacts of sampling and analysis choice in recovering the direction of that predefined preference.

# Methods

``` {r openOptions}
optionsCompleteList <- readRDS(here::here("data", "optionsCompleteList.rds"))
```

## Simulating the Scenarios

* Landscape simulation.

* abmAnimalMovement settings

We used the animal movement using abmAnimalMovement `r paste0("v.", packageVersion("abmAnimalMovement"))` [@abmAnimalMovement] to simulate the movement data of an animal with a predefined (i.e., known) habitat preference.
The abmAnimalMovement package provides an agent-based approach to simulating terrestrial animal movement using raster environmental data to guie the animals decisions.
We used the NLMR `r paste0("v.", packageVersion("NLMR"))` package [@NLMR] to generate the three required resource/environmental rasters: movement resistance, foraging quality, and shelter site quality.
The abmAnimalMovement package has systems for simulating activity cycles, three separate behavioural states (differing in movement characteristics and resource prioritisation), and site fidelity.
For the purposes of this study we used one of the pre-created example pseudo-species: Badger, described in the package manuscript.
In brief, the badger is a terrestrial species occupying several shelter sites, with a 8-12 hour activity cycle with minor seasonal variation, and is subject to differing movement resistance across the landscape.

For the purposes of the analysis we simplified the landscape information into categories â€“akin to the sort of land-use information more frequently available to researchers of animal movement.
We focused on foraging quality because it influences the greatest amounts of movement compared to sheltering or exploratory movements.
<!-- SHOULD WE CHANGE THE FACTOR 1 becuase it is easier to remember? -->
We converted the continuous foraging quality raster into a binary, where higher quality areas (greater than 0.5) are classed as 2, and lower quality areas as 0.

We used that simulated landscape and abmAnimalMovement to simulate a population of  `r length(optionsCompleteList$individuals$individual)`, that later can be sampled from.
All individuals of this population had the same simulation settings apart from starting location.
Therefore, the variation between individuals is due to stochasticity rather than variation in the predefined habitat preference.

## Sampling and Analysis Options

* targets construction

To manage the sampling of the population and the compounding growth of subsequent analysis decisions, we used the targets `r paste0("v.", packageVersion("targets"))` and tarchetypes `r paste0("v.", packageVersion("tarchetypes"))` R packages [@targets; @tarchetypes].
These packages allowed branching workflow pipeline, while keeping track of object creation thereby optimising the compute time required to explore the multiverse of analysis choice.

### Sampling

* tracking regime

* sample size

The first decision in most animal movement studies will be concerning tracking regime.
This decision is frequently dictated by more practical considerations such as anatomy and behaviour of the animal, cost of the tracking devices, and environmental factors.
Here we aimed to cover a range of tracking regimes that vary in the frequency of location fixes (`r paste0(round(1/min(optionsCompleteList$regime$tf), digits = 2), " to ", round(1/max(optionsCompleteList$regime$tf), digits = 2))` points per hour), and the total duration of tracking (`r paste0(min(optionsCompleteList$regime$td), " to ", max(optionsCompleteList$regime$td))` days).
We created sub-sampled datasets based on every combination of tracking frequencies and durations, provided they would result in greater than 30 data points per individual.

An important component of assessing population level habitat selection is the number of individuals included in analysis.
Therefore, we randomly generated a number of samples from our population of `r length(optionsCompleteList$individuals$individual)` simulated individuals.
We varied these samples sizes from `r paste0(min(sapply(optionsCompleteList$samples, length)), " to ", max(sapply(optionsCompleteList$samples, length)))` individuals, and ran `r optionsCompleteList$repeats` repeats for each size.
A sample never mixed tracking regimes.

### Analysis

Building on the decisions concerning tracking regime and population sampling, our multiverse expanded dramatically by exploring four primary analysis routes.
These routes included an area based approach using Compana analysis, and three step-based approaches including averaged individual step-selection models, two-step conditional regression models, and a Poisson model.

* area based: compana, area method, contour, available points, space sampling, type II/III, compana test

We ran the Compana analysis (Compositional Analysis of Habitat Use) using the *adehabitatHS* `r paste0("v.", packageVersion("adehabitatHS"))` [@adehabitatHS].
Compana allows for the assessment of habitat selection of multiple animals in defined habitat types; it also allows habitat selection to be estimated at different scales.
We explored two scales in the multiverse: selection within the home range (Type III), and selection within an overall population available area (Type II).
The former design (Type III) requires availability habitats to be defined on an individual-by-individual basis, while the latter (Type II) design uses a summarised population level availability.
<!-- Aebischer, N. J. and Robertson, P. A. (1992) Practical aspects of compositional analysis as applied to pheasant habitat utilisation. pp. 285â€“293 In: Priede, G. and Swift, S. M. Wildlife telemetry, remote monitoring and tracking of animals. -->
<!-- Aebischer, N. J., Robertson, P. A. and Kenward, R. E. (1993) Compositional analysis of habitat use from animal radiotracking data. Ecology, 74, 1313â€“1325. -->
<!-- Johnson, D. H. (1980) The comparison of usage and availability measurements for evaluating resource preference. Ecology, 61, 65â€“71. -->

To define availability, we created home range polygons then sampled points within, recovering the corresponding habitat at those points.
The home range (aka availability) polygons can be generated via many different processes.
We selected to explore `r paste(optionsCompleteList$area$areaMethod, collapse = " and ")` (Minimum Convex Polygons, Autocorrelated Kernel Density Estimators).
We used the *ctmm* `r paste0("v.", packageVersion("ctmm"))` [@ctmm] package for the creation of AKDEs, and the  *adehabitatHR* `r paste0("v.", packageVersion("adehabitatHR"))` [@adehabitatHR] package for the MCPs.
The AKDEs required the fitting of a movement model, we fit multiple models and selected the top scoring model by AIC.
For the best model we followed recommendations of <!-- INES PAPER HERE -->, opting to run AKDEs as weighted and using (PREML???) as both these options tend to be the most robust in scenarios of lower tracking frequencies.
There are many options involved in the creation of AKDEs that could shape habitat availability and therefore estimations of selection.
We avoided a deeper exploration as the impact of the internal AKDE choices are likely smaller than those between area methods (e.g., compared to MCPs), and the AKDE creation can more guided by the underlying data.
By comparison the MCPs have very few options inpacting their creation.
Mainly MCP size varies based on the percentage of outliers excluded from the polygon area.
For all area methods we vary this percentage: `r paste(optionsCompleteList$area$areaContour, collapse = "%, ")`%, that correspond to increasingly large areas included in the availability polygon (i.e., covering areas that are less used by the individual).
We selected these contour values as they are the most frequently used in spatial studies <!-- CRANE ET AL HERE -->

Once we had created all areas for each individual, for every combination of tracking regime (duration x frequency, total regimes: `r nrow(optionsCompleteList$regime)`), we created the sample/population available areas by combining all polygons.
We used this combined polygon for the type II design, where all individuals have the same availability.

We used the availability polygons to define the extent within which we sampled habitat characteristics.
The habitat characteristics were extracted from the classified landscape raster at various points.
We varied both the number of points generated (`r paste0(min(optionsCompleteList$area$Method_ap), " to ", max(optionsCompleteList$area$Method_ap))`), as well as the pattern of how they were distributed within the polygon (random or stratified).

The final decision in the area based method approach was whether the Compana analysis was tested using randomisation or in a parametric fashion.
The former uses randomisation tests to estimate the habitat selection, while the latter uses chi-squared.

* ssf: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles, Model Averaging Method
* twoStep: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles
* poisson: Model Formula (SSF or iSSF), Available Points per Step, Distribution of Step Lengths, Distribution of Turn Angles

The other analysis pathways do not rely on an available area, instead they focus on randomly generated steps that mirror the observed movement of the animal.
As such the decisions involved in running the step-selection, two-step conditional regression, and Poisson models are largely the same.

The first decision is the number of random steps generated per observed step; we ranged this from `r paste0(min(optionsCompleteList$ssf$MethodSSF_as), " to ", max(optionsCompleteList$ssf$MethodSSF_as))`.
The generation of random steps is guided by two distributions, one describing the step lengths from the last observed location, and another describing the turn angle from the last observed direction of travel.
We chose to explore the impacts of different distributions.
For the step length we explored gamma and exponential distributions; for the turn angle we explored Von Mises and uniform.

All the step-based methods require the definition of a formula, where use/available is predicted by the habitat characteristics at those locations.
Model formulation opens up many possible alternative routes of analysis, but for this exploration we focus on the impacts of integrating step and turn angle interactions with habitat characteristics.
We ran two versions of all models, one with no interactions and one where both step lengths and turn angles interaction with the habitat classification.
Previous work has suggested that the integrated (i.e., model with interactions) performs better <!-- CITE paper on iSSF, and make sure to clarify the extact benefit -->

A key component of all the population approaches is how they translate a highly structured dataset into a overall summary.
We ran individual step selection models using the amt `r paste0("v.", packageVersion("amt"))` [@amt] package, to explore rudimentary summary methods. <!-- there is a paper suggesting exploring the or modelling the effects is an ok route to go -->
The individual step selection models need to be averaged in some manner to extract a population mean selection.
We explore two simple options for achieving this: a naive mean of the final estimates (i.e., a mean of the estimated betas), and a model average using the *MuMIn* `r paste0("v.", packageVersion("MuMIn"))` package [@MuMIn].
The *MuMIn* model average approach is weighted based on AICc.
However, AICc is not directly comparable between models fitted with different datasets.
As the model formulas are identically complex and the datasets equal in data quantity, the differences in AIC are purely describing the goodness of fit to the different datasets.
Therefore, the model average provided is weighted by model fit.

The difficulties model averaging models based on different data has led to the creation of models that account for the individual variably in the model formula.
A Two-Step Conditional Regression is one such solution, where strata (time steps) and clusters (individual animals) are accounted for.
<!-- NEED MORE DETAILS HERE -->
<!-- Craiu, R.V., Duchesne, T., Fortin, D. and Baillargeon, S. (2011), Conditional Logistic Regression with Longitudinal Follow-up and Individual-Level Random Coefficients: A Stable and Efficient Two-Step Estimation Method, Journal of Computational and Graphical Statistics. 20(3), 767-784. -->
We implemented these models using the *TwoStepCLogit* `r paste0("v.", packageVersion("TwoStepCLogit"))` [@TwoStepCLogit] package.

More recently @muff_accounting_2020 have suggested a reformulation of the step selection models to provide faster reliable estimations of population habitat selection.
The suggestion is to reformulate the model as a Poisson model, but critically with fixed <!-- fill in specifics here --> .
To avoid the slow convergence of MCMC estimation, @muff_accounting_2020 make use of integrated nested Laplace approximation (INLA) to approximate Bayesian inference.
We followed the code provided by @muff_accounting_2020 and made use of *INLA* `r paste0("v.", packageVersion("INLA"))` [@rue_approximate_2009; @lindgren_explicit_2011; @martins_bayesian_2013; @rue_bayesian_2017; @kourounis_towards_2018] to run Poisson models to estimate habitat selection.

## Assessing the multiverse

* spec curves

Specification curves provide an overview of the estimates of a given range of analyses.
Tighter more steep curves suggest greater agreement between all the analysis end points.
Here we also plotted the estimates against the different decisions that results in the estimates, allowing direct comparison on how the decision impacts the variation in the estimates.

* brm models: one per each analysis method

To better detect the impact of decisions, while accounting for the random variation stemming from the differences in individuals/samples, we ran a number of Bayesian Regression Models.
The Bayesian Regression Models aimed to describe how much of the deviation from a median answer could be explained by the various sampling and analysis decisions.
For each analysis route we ran a model that included tracking frequency, tracking duration, sample size, and all the corresponding analysis choices.
All continuous variables were scaled to help determine their relative importance to each other: (x - mean(x))/sd(x).
<!-- add actually variation in variables -->
For the area based Compana approach the population effects included: the continuous variable contour (continuous); and the categoric predictors sampling pattern (random, stratified), test (randomisation, parametric), area method (AKDE, MCP), and design type (II, III).
For the step-based approaches they all included: model formula (integrated, non-integrated), step distribution (gamma, exponential), turn distribution (Von Mises, uniform).
The step-selection model approach also included: averaging method (naive, MuMIn average).

We ran the Bayesian Regression Models using the *brms* `r paste0("v.", packageVersion("brms"))` [@brms] package.
Once complete, we checked model convergence using rhat values, acf, and trace plots.
After assessment of the model convergence measures, we modified the running parameters <!-- [FINAL VALUES HERE: warmup = 200, iter = 1000, chains = 4, adapt_delta = 0.90, max_treedepth = 15] -->.

# Results

## Specification Curves

(Fig. \@ref(fig:specCurveArea)).

```{r specCurveArea, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Spec curve"}
knitr::include_graphics(here::here("notebook", "figures", "area_specCurve.png"))
```

(Fig. \@ref(fig:specCurveSSF)).

```{r specCurveSSF, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Spec curve"}
knitr::include_graphics(here::here("notebook", "figures", "ssf_specCurve.png"))
```

(Fig. \@ref(fig:specCurveTwoStep)).

```{r specCurveTwoStep, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Spec curve"}
knitr::include_graphics(here::here("notebook", "figures", "twoStep_specCurve.png"))
```

(Fig. \@ref(fig:specCurvePois)).

```{r specCurvePois, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Spec curve"}
knitr::include_graphics(here::here("notebook", "figures", "pois_specCurve.png"))
```

## Model Results

The conditional *R^2^* values differed for the three models. The Compana results model had a conditional *R^2^* of `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "areaBrms" & modelExtracts$r2Outputs$Component == "conditional"], digits = 2)`; whereas the SSF model returned `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "ssfBrms" & modelExtracts$r2Outputs$Component == "conditional"], digits = 2)`, and the Poisson model returned `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "poisBrms" & modelExtracts$r2Outputs$Component == "conditional"], digits = 2)`.

The marginal *R^2^* represents the bulk of the conditional *R^2^* suggesting an important role for the fixed/population effects. The Compana results model had a conditional *R^2^* of `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "areaBrms" & modelExtracts$r2Outputs$Component == "marginal"], digits = 2)`; whereas the SSF model returned `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "ssfBrms" & modelExtracts$r2Outputs$Component == "marginal"], digits = 2)`, and the Poisson model returned `r round(modelExtracts$r2Outputs$R2[modelExtracts$r2Outputs$model == "poisBrms" & modelExtracts$r2Outputs$Component == "marginal"], digits = 2)`.

```{r test}





```
The sample size was negatively correlated with deviation from the median estimate ($\beta$ `r round(modelExtracts$betasOutputs[modelExtracts$betasOutputs$model == "ssfBrms" & modelExtracts$betasOutputs$.variable == "b_sampleSizeScaled",]$.value, digits = 2)`; 95% HDCI `r paste(round(c(modelExtracts$betasOutputs[modelExtracts$betasOutputs$model == "ssfBrms" & modelExtracts$betasOutputs$.variable == "b_sampleSizeScaled",]$.lower, modelExtracts$betasOutputs[modelExtracts$betasOutputs$model == "ssfBrms" & modelExtracts$betasOutputs$.variable == "b_sampleSizeScaled",]$.upper), digits = 2), collapse = " - ")`).


(Fig. \@ref(fig:effectPlotArea)).

```{r effectPlotArea, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}

knitr::include_graphics(here::here("notebook", "figures", "areaBrms_effectsPlot.png"))
```

(Fig. \@ref(fig:effectPlotSSF)).

```{r effectPlotSSF, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
knitr::include_graphics(here::here("notebook", "figures", "ssfBrms_effectsPlot.png"))
```

(Fig. \@ref(fig:effectPlotTwoStep)).

```{r effectPlotTwoStep, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
knitr::include_graphics(here::here("notebook", "figures", "twoStepBrms_effectsPlot.png"))
```

(Fig. \@ref(fig:effectPlotPois)).

```{r effectPlotPois, echo=FALSE, out.width='100%', fig.height=5, fig.width=3, fig.align="centre", fig.cap="Beta coefs"}
knitr::include_graphics(here::here("notebook", "figures", "poisBrms_effectsPlot.png"))
```

# Discussion

## Limitations

## Conclusions

# Acknowledgements

BMM was funded by the Natural Environment Research Council (NERC) via the IAPETUS2 Doctoral Training Partnership.

# Software availablity

In addition to packages already mentioned in the methods we also used the following.

We used *R* `r paste0("v.", version$major, ".", version$minor)` [@base] via *RStudio* v.2023.6.2.561 [@rstudio]. <!-- version has to be manually added because rstudioapi doesn't work in targets -->
We used *here* `r paste0("v.", packageVersion("here"))` [@here] and *qs* `r paste0("v.", packageVersion("qs"))` [@qs] to manage directory addresses and saved objects.

We used *raster* `r paste0("v.", packageVersion("raster"))` [@raster] and *RandomFields* `r paste0("v.", packageVersion("RandomFields"))` [@RandomFields] to aid landscape raster creation alongside NLMR `r paste0("v.", packageVersion("NLMR"))` [@NLMR].

We used *ggplot2* `r paste0("v.", packageVersion("ggplot2"))` for creating figures [@ggplot2], with the expansions: *patchwork* `r paste0("v.", packageVersion("patchwork"))` [@patchwork], *ggridges* `r paste0("v.", packageVersion("ggridges"))` [@ggridges], and *ggdist* `r paste0("v.", packageVersion("ggdist"))` [@ggdist].

We used *brms* `r paste0("v.", packageVersion("brms"))` [@brms] to run Bayesian models, with diagnostics generated used *bayesplot* `r paste0("v.", packageVersion("bayesplot"))` [@bayesplot], *tidybayes* `r paste0("v.", packageVersion("tidybayes"))` [@tidybayes], and *performance* `r paste0("v.", packageVersion("performance"))` [@performance].

We used the *dplyr* `r paste0("v.", packageVersion("dplyr"))` [@dplyr], *tibble* `r paste0("v.", packageVersion("tibble"))` [@tibble],
<!-- *reshape2* `r paste0("v.", packageVersion("reshape2"))` [@reshape2], -->
and *stringr* `r paste0("v.", packageVersion("stringr"))` [@stringr] packages for data manipulation.

We used *sp* `r paste0("v.", packageVersion("sp"))` [@sp], *move* `r paste0("v.", packageVersion("move"))` [@move] for manipulation of spatial data and estimation of space use not otherwise mentioned in the methods.

We used rmarkdown `r paste0("v.", packageVersion("rmarkdown"))` [@rmarkdown2023; @rmarkdown2018; @rmarkdown2020], bookdown `r paste0("v.", packageVersion("bookdown"))` [@bookdown2016; @R-bookdown], tinytex `r paste0("v.", packageVersion("tinytex"))` [@tinytex2019; @tinytex2023], and knitr `r paste0("v.", packageVersion("knitr"))` [@knitr2015; @knitr2014; @knitr2023] packages to generate type-set outputs.

We generated R package citations with the aid of *grateful* `r paste0("v.", packageVersion("grateful"))` [@grateful].

# Data availabilty

<!-- add zenodo archived snapshot of github -->

# Supplementary Material

# References
